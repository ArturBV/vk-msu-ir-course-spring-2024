{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02e2af1-998e-4b33-8220-62270916d947",
   "metadata": {},
   "source": [
    "# Машинное обучение ранжированию с использованием библиотеки CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом примере мы:\n",
    "- увидим как выглядят датасеты для машинного обучения ранжированию, на примере стандартного датасета [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- познакомимся с библиотекой **CatBoost**\n",
    "- научимся решать задачу машинного обучения ранжирования используя алгоритмы, реализованные в **CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import catboost\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Скачиваем датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Дальше мы будем работать с датасетом MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Мы этого делать не будем т.к. в CatBoost уже встроена возможность загрузить небольшой сабсет MSLR, с которым мы и будем работать дальше.\n",
    "\n",
    "Загрузим этот сабсет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61225ba7-5615-4e17-93e3-cbf592d3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = catboost.datasets.msrank_10k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994de0-9f4a-4582-91f4-8ae1813b0df3",
   "metadata": {},
   "source": [
    "Датасет представляет собой обычный табличный датасет из 130 колонок:\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит query_id, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b053cf6f-71de-41a9-a255-6e6ce91ea0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8         9    ...  128       129  \\\n",
      "0  2.0    1    3    3    0    0    3  1.0  1.0  0.000000  ...   62  11089534   \n",
      "1  2.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   54  11089534   \n",
      "2  0.0    1    3    0    2    0    3  1.0  0.0  0.666667  ...   45         3   \n",
      "3  2.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   56  11089534   \n",
      "4  1.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   64         5   \n",
      "5  1.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   62         6   \n",
      "6  1.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   62         6   \n",
      "7  2.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   73         0   \n",
      "8  1.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   51  11089534   \n",
      "9  0.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   48         1   \n",
      "\n",
      "   130  131    132  133  134  135  136  137  \n",
      "0    2  116  64034   13    3    0    0  0.0  \n",
      "1    2  124  64034    1    2    0    0  0.0  \n",
      "2    1  124   3344   14   67    0    0  0.0  \n",
      "3   13  123  63933    1    3    0    0  0.0  \n",
      "4    7  256  49697    1   13    0    0  0.0  \n",
      "5    7  210  49923    5   15    0    0  0.0  \n",
      "6    7  256  50023    3   14    0    0  0.0  \n",
      "7   17  115  63318    1    3    0    0  0.0  \n",
      "8   15  124  63363    1    3    0    0  0.0  \n",
      "9    1  541  63363    1    5    0    0  0.0  \n",
      "\n",
      "[10 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d21-056f-42d8-a007-966444ab0996",
   "metadata": {},
   "source": [
    "Для удобства присвоим колонкам говорящие имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027e3c18-6103-4914-a872-cbc7879fce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "# Assign column names\n",
    "columns = generate_column_names(num_features=136)\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cb1b-4ad1-438f-b6d8-fd1676c34683",
   "metadata": {},
   "source": [
    "Теперь наши данные выглядят красивее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916f781c-8850-4dae-b619-cdc7ac0cc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  qid  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    2.0    1          3          3          0          0          3   \n",
      "1    2.0    1          3          0          3          0          3   \n",
      "2    0.0    1          3          0          2          0          3   \n",
      "3    2.0    1          3          0          3          0          3   \n",
      "4    1.0    1          3          0          3          0          3   \n",
      "\n",
      "   feature_6  feature_7  feature_8  ...  feature_127  feature_128  \\\n",
      "0        1.0        1.0   0.000000  ...           62     11089534   \n",
      "1        1.0        0.0   1.000000  ...           54     11089534   \n",
      "2        1.0        0.0   0.666667  ...           45            3   \n",
      "3        1.0        0.0   1.000000  ...           56     11089534   \n",
      "4        1.0        0.0   1.000000  ...           64            5   \n",
      "\n",
      "   feature_129  feature_130  feature_131  feature_132  feature_133  \\\n",
      "0            2          116        64034           13            3   \n",
      "1            2          124        64034            1            2   \n",
      "2            1          124         3344           14           67   \n",
      "3           13          123        63933            1            3   \n",
      "4            7          256        49697            1           13   \n",
      "\n",
      "   feature_134  feature_135  feature_136  \n",
      "0            0            0          0.0  \n",
      "1            0            0          0.0  \n",
      "2            0            0          0.0  \n",
      "3            0            0          0.0  \n",
      "4            0            0          0.0  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Проведем небольшой EDA.\n",
    "\n",
    "Всего у нас 10000 документов в трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2ad7b6-a90a-4eda-a47f-ec9b407cd12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float64(97), int64(41)\n",
      "memory usage: 10.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360312-89be-4d21-af28-7c24e7871e89",
   "metadata": {},
   "source": [
    "И 10000 документов в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64e99fd-93a4-4a60-af94-7e81c7615504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float64(97), int64(41)\n",
      "memory usage: 10.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7932d-b65e-4b33-b468-c4ef727f4aa6",
   "metadata": {},
   "source": [
    "Сколько у нас всего запросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c337181-5898-4889-8e4d-ccc872aea83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 87 train and 88 test queries\n"
     ]
    }
   ],
   "source": [
    "num_queries_train = df_train['qid'].nunique()\n",
    "num_queries_test = df_test['qid'].nunique()\n",
    "print(f\"Got {num_queries_train} train and {num_queries_test} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd93a2-8714-473c-9a0a-259749f651a3",
   "metadata": {},
   "source": [
    "Получается, у примерно по 100 документов на запрос.\n",
    "\n",
    "Это типично, когда, например, для сбора датасета обкачивались и заливались на оценку топ-100 документов поисковой выдачи по случайным запросам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8ba6b-aef3-4a13-884e-65da7f014abd",
   "metadata": {},
   "source": [
    "Какие у нас таргеты (оценки?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e427aaa-d453-4843-b824-4ebfb7897955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    5481\n",
      "1.0    3000\n",
      "2.0    1326\n",
      "3.0     142\n",
      "4.0      51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec1d3dc2-54f6-46d1-b238-daed3743a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    5755\n",
      "1.0    2830\n",
      "2.0    1221\n",
      "3.0     148\n",
      "4.0      46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fddaa-d7ba-453a-aa5f-5bc834be9951",
   "metadata": {},
   "source": [
    "Конвертируем датасет в формате, который можно подавать на вход модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f15870f-9459-48d7-a69d-5cd26c23f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_catboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_catboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_catboost_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Нормализуем оценки релевантностей, и попутно запомним исходной вектор таргетов чтобы потом использовать его для расчета метрик качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b2bbcb-4b74-4bd1-8554-807fea5e5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = 4\n",
    "y_train /= y_max\n",
    "y_test_orig = y_test.copy()\n",
    "y_test /= y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0534f6-713f-4fa1-83c6-5d20104c1495",
   "metadata": {},
   "source": [
    "Подготовим пулы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22758401-b1aa-4eee-a6d5-2dfc257ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_train = catboost.Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "pool_test = catboost.Pool(data=X_test, label=y_test, group_id=q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f73c0-7873-4676-aad0-7eeb1f1a78f7",
   "metadata": {},
   "source": [
    "Зададим целевую метрику, которую будем пытаться оптимизировать.  \n",
    "В нашем случае будем использовать NDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d34305a-86c9-429b-b571-dd3d132c5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRIC = 'NDCG:top=10;type=Exp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb13c5-d705-4f42-85cd-e19e5ea66e1f",
   "metadata": {},
   "source": [
    "Параметры обучения модели:\n",
    "- зададим целевую метрику\n",
    "- фиксируем сид генератора случайных чисел\n",
    "- зададим число итераций, после которого останавливаем обучение если в течение данного числа итераций мы не наблюдаем улучшения целевой метрики на валидационном множесте\n",
    "\n",
    "Для обучения на GPU надо добавить параметр *task_type: GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1842e3be-6a55-4baf-a2e7-6bf63a2a2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'iterations': 2000,             # maximum number of trees\n",
    "    'early_stopping_rounds': 200,   # stop if metric does not improve for N rounds\n",
    "    'eval_metric': EVAL_METRIC,\n",
    "    'random_seed': 22,\n",
    "    'verbose': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3700ad-b190-4ea5-aa5f-e2999284f73f",
   "metadata": {},
   "source": [
    "Мы будем обучать разные модели, использующие разные лоссы, соответствующие разным алгоритмам Learning to Rank.  \n",
    "Напишем функцию, которая позволит кастомизировать модель под нужный лосс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1caad53-8a10-4a91-bfd5-58399c0fd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(loss_function):\n",
    "    params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "\n",
    "    # Temporary that is used by catboost to store additional information\n",
    "    catboost_info_dir = f\"/tmp/catboost_info.{loss_function.lower()}\"\n",
    "\n",
    "    params.update({\n",
    "        'loss_function': loss_function,\n",
    "        'train_dir': str(catboost_info_dir),\n",
    "    })\n",
    "    return catboost.CatBoost(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a3880-e714-4d18-a1a9-9234d01db4dc",
   "metadata": {},
   "source": [
    "Создадим и обучим pointwise модель которая в качестве лосса используем обычное RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f093276-08d9-462a-af6a-39a7e6fd0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.047893\n",
      "0:\ttest: 0.2836948\tbest: 0.2836948 (0)\ttotal: 87.9ms\tremaining: 2m 55s\n",
      "10:\ttest: 0.4296218\tbest: 0.4296218 (10)\ttotal: 168ms\tremaining: 30.5s\n",
      "20:\ttest: 0.4432635\tbest: 0.4436566 (19)\ttotal: 245ms\tremaining: 23.1s\n",
      "30:\ttest: 0.4443193\tbest: 0.4471698 (29)\ttotal: 318ms\tremaining: 20.2s\n",
      "40:\ttest: 0.4501459\tbest: 0.4522379 (36)\ttotal: 392ms\tremaining: 18.7s\n",
      "50:\ttest: 0.4568131\tbest: 0.4568131 (50)\ttotal: 464ms\tremaining: 17.7s\n",
      "60:\ttest: 0.4604295\tbest: 0.4609420 (59)\ttotal: 537ms\tremaining: 17.1s\n",
      "70:\ttest: 0.4570174\tbest: 0.4609420 (59)\ttotal: 607ms\tremaining: 16.5s\n",
      "80:\ttest: 0.4586053\tbest: 0.4609420 (59)\ttotal: 681ms\tremaining: 16.1s\n",
      "90:\ttest: 0.4623113\tbest: 0.4644785 (88)\ttotal: 752ms\tremaining: 15.8s\n",
      "100:\ttest: 0.4656290\tbest: 0.4656290 (100)\ttotal: 821ms\tremaining: 15.4s\n",
      "110:\ttest: 0.4639706\tbest: 0.4664429 (101)\ttotal: 894ms\tremaining: 15.2s\n",
      "120:\ttest: 0.4674214\tbest: 0.4677040 (119)\ttotal: 971ms\tremaining: 15.1s\n",
      "130:\ttest: 0.4688286\tbest: 0.4706122 (128)\ttotal: 1.05s\tremaining: 14.9s\n",
      "140:\ttest: 0.4698357\tbest: 0.4716265 (133)\ttotal: 1.12s\tremaining: 14.8s\n",
      "150:\ttest: 0.4675644\tbest: 0.4716265 (133)\ttotal: 1.2s\tremaining: 14.6s\n",
      "160:\ttest: 0.4676738\tbest: 0.4716265 (133)\ttotal: 1.26s\tremaining: 14.4s\n",
      "170:\ttest: 0.4697995\tbest: 0.4716265 (133)\ttotal: 1.33s\tremaining: 14.3s\n",
      "180:\ttest: 0.4734475\tbest: 0.4745322 (175)\ttotal: 1.41s\tremaining: 14.1s\n",
      "190:\ttest: 0.4746428\tbest: 0.4755441 (187)\ttotal: 1.48s\tremaining: 14s\n",
      "200:\ttest: 0.4740701\tbest: 0.4773202 (197)\ttotal: 1.55s\tremaining: 13.8s\n",
      "210:\ttest: 0.4752314\tbest: 0.4781764 (203)\ttotal: 1.62s\tremaining: 13.7s\n",
      "220:\ttest: 0.4756878\tbest: 0.4790506 (213)\ttotal: 1.69s\tremaining: 13.6s\n",
      "230:\ttest: 0.4756776\tbest: 0.4790506 (213)\ttotal: 1.76s\tremaining: 13.5s\n",
      "240:\ttest: 0.4784865\tbest: 0.4804958 (238)\ttotal: 1.83s\tremaining: 13.4s\n",
      "250:\ttest: 0.4785600\tbest: 0.4804958 (238)\ttotal: 1.91s\tremaining: 13.3s\n",
      "260:\ttest: 0.4755141\tbest: 0.4804958 (238)\ttotal: 1.98s\tremaining: 13.2s\n",
      "270:\ttest: 0.4752647\tbest: 0.4804958 (238)\ttotal: 2.06s\tremaining: 13.2s\n",
      "280:\ttest: 0.4756516\tbest: 0.4804958 (238)\ttotal: 2.15s\tremaining: 13.1s\n",
      "290:\ttest: 0.4760176\tbest: 0.4804958 (238)\ttotal: 2.23s\tremaining: 13.1s\n",
      "300:\ttest: 0.4737687\tbest: 0.4804958 (238)\ttotal: 2.32s\tremaining: 13.1s\n",
      "310:\ttest: 0.4792477\tbest: 0.4804958 (238)\ttotal: 2.4s\tremaining: 13s\n",
      "320:\ttest: 0.4750696\tbest: 0.4804958 (238)\ttotal: 2.48s\tremaining: 13s\n",
      "330:\ttest: 0.4769019\tbest: 0.4804958 (238)\ttotal: 2.56s\tremaining: 12.9s\n",
      "340:\ttest: 0.4761462\tbest: 0.4804958 (238)\ttotal: 2.65s\tremaining: 12.9s\n",
      "350:\ttest: 0.4778792\tbest: 0.4804958 (238)\ttotal: 2.73s\tremaining: 12.8s\n",
      "360:\ttest: 0.4786323\tbest: 0.4804958 (238)\ttotal: 2.8s\tremaining: 12.7s\n",
      "370:\ttest: 0.4775911\tbest: 0.4804958 (238)\ttotal: 2.88s\tremaining: 12.7s\n",
      "380:\ttest: 0.4750394\tbest: 0.4804958 (238)\ttotal: 2.97s\tremaining: 12.6s\n",
      "390:\ttest: 0.4752301\tbest: 0.4804958 (238)\ttotal: 3.05s\tremaining: 12.6s\n",
      "400:\ttest: 0.4756559\tbest: 0.4804958 (238)\ttotal: 3.12s\tremaining: 12.5s\n",
      "410:\ttest: 0.4770354\tbest: 0.4804958 (238)\ttotal: 3.19s\tremaining: 12.4s\n",
      "420:\ttest: 0.4756163\tbest: 0.4804958 (238)\ttotal: 3.27s\tremaining: 12.3s\n",
      "430:\ttest: 0.4772454\tbest: 0.4804958 (238)\ttotal: 3.35s\tremaining: 12.2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.4804958294\n",
      "bestIteration = 238\n",
      "\n",
      "Shrink model to first 239 iterations.\n",
      "model fit: elapsed = 3.512 num_trees = 239\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_model('RMSE')\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"model fit: elapsed = {elapsed:.3f} num_trees = {model.tree_count_}\")\n",
    "\n",
    "# Save model\n",
    "# model.save_model(\"/tmp/model.cbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89c7a-0987-4831-98f1-989f75240acf",
   "metadata": {},
   "source": [
    "Получим предикты модели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e00327b-7005-44dc-990f-bc9ec5573368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got predictions\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = model.predict(pool_test)\n",
    "print(\"got predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Посчиатем метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric = NDCG:top=10;type=Exp score = 0.427\n",
      "metric = DCG:top=10;type=Exp score = 8.766\n",
      "metric = MAP:top=10 score = 0.535\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp', 'DCG:top=10;type=Exp', 'MAP:top=10']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "    \n",
    "# Compute metrics on test using original (non-normalized) labels\n",
    "compute_metrics(y_test_orig, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48a3c-095c-4db0-8d49-8ed7fd488625",
   "metadata": {},
   "source": [
    "Теперь проделаем все то же самое, но с использованием алгоритма YetiRank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce16b132-99ce-499b-bcdd-539d67008f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.3331801\tbest: 0.3331801 (0)\ttotal: 48.4ms\tremaining: 1m 36s\n",
      "10:\ttest: 0.4529994\tbest: 0.4529994 (10)\ttotal: 231ms\tremaining: 41.7s\n",
      "20:\ttest: 0.4559417\tbest: 0.4566992 (12)\ttotal: 398ms\tremaining: 37.5s\n",
      "30:\ttest: 0.4501092\tbest: 0.4574508 (22)\ttotal: 573ms\tremaining: 36.4s\n",
      "40:\ttest: 0.4658935\tbest: 0.4658935 (40)\ttotal: 740ms\tremaining: 35.3s\n",
      "50:\ttest: 0.4646162\tbest: 0.4693073 (45)\ttotal: 900ms\tremaining: 34.4s\n",
      "60:\ttest: 0.4674726\tbest: 0.4700926 (58)\ttotal: 1.08s\tremaining: 34.4s\n",
      "70:\ttest: 0.4718160\tbest: 0.4718160 (70)\ttotal: 1.28s\tremaining: 34.7s\n",
      "80:\ttest: 0.4738091\tbest: 0.4738091 (80)\ttotal: 1.44s\tremaining: 34.2s\n",
      "90:\ttest: 0.4735125\tbest: 0.4762371 (82)\ttotal: 1.6s\tremaining: 33.6s\n",
      "100:\ttest: 0.4729083\tbest: 0.4762371 (82)\ttotal: 1.77s\tremaining: 33.3s\n",
      "110:\ttest: 0.4700168\tbest: 0.4762371 (82)\ttotal: 1.93s\tremaining: 32.8s\n",
      "120:\ttest: 0.4838545\tbest: 0.4838545 (120)\ttotal: 2.09s\tremaining: 32.4s\n",
      "130:\ttest: 0.4772189\tbest: 0.4838545 (120)\ttotal: 2.25s\tremaining: 32.1s\n",
      "140:\ttest: 0.4779851\tbest: 0.4838545 (120)\ttotal: 2.42s\tremaining: 31.9s\n",
      "150:\ttest: 0.4807726\tbest: 0.4838545 (120)\ttotal: 2.58s\tremaining: 31.7s\n",
      "160:\ttest: 0.4816139\tbest: 0.4840915 (156)\ttotal: 2.75s\tremaining: 31.4s\n",
      "170:\ttest: 0.4867149\tbest: 0.4876239 (169)\ttotal: 2.91s\tremaining: 31.1s\n",
      "180:\ttest: 0.4859653\tbest: 0.4876239 (169)\ttotal: 3.07s\tremaining: 30.9s\n",
      "190:\ttest: 0.4846243\tbest: 0.4876239 (169)\ttotal: 3.23s\tremaining: 30.6s\n",
      "200:\ttest: 0.4861013\tbest: 0.4876239 (169)\ttotal: 3.39s\tremaining: 30.4s\n",
      "210:\ttest: 0.4883252\tbest: 0.4883252 (210)\ttotal: 3.55s\tremaining: 30.1s\n",
      "220:\ttest: 0.4903520\tbest: 0.4909489 (219)\ttotal: 3.72s\tremaining: 29.9s\n",
      "230:\ttest: 0.4933942\tbest: 0.4933942 (230)\ttotal: 3.89s\tremaining: 29.8s\n",
      "240:\ttest: 0.4941384\tbest: 0.4945190 (237)\ttotal: 4.05s\tremaining: 29.6s\n",
      "250:\ttest: 0.4973020\tbest: 0.4978780 (246)\ttotal: 4.22s\tremaining: 29.4s\n",
      "260:\ttest: 0.4965145\tbest: 0.4990831 (256)\ttotal: 4.38s\tremaining: 29.2s\n",
      "270:\ttest: 0.4980687\tbest: 0.4990831 (256)\ttotal: 4.54s\tremaining: 29s\n",
      "280:\ttest: 0.5030621\tbest: 0.5030621 (280)\ttotal: 4.7s\tremaining: 28.7s\n",
      "290:\ttest: 0.5025916\tbest: 0.5034271 (288)\ttotal: 4.85s\tremaining: 28.5s\n",
      "300:\ttest: 0.5013384\tbest: 0.5048672 (294)\ttotal: 5.02s\tremaining: 28.3s\n",
      "310:\ttest: 0.5008369\tbest: 0.5048672 (294)\ttotal: 5.18s\tremaining: 28.1s\n",
      "320:\ttest: 0.4988200\tbest: 0.5048672 (294)\ttotal: 5.35s\tremaining: 28s\n",
      "330:\ttest: 0.4981759\tbest: 0.5048672 (294)\ttotal: 5.52s\tremaining: 27.8s\n",
      "340:\ttest: 0.4962236\tbest: 0.5048672 (294)\ttotal: 5.68s\tremaining: 27.6s\n",
      "350:\ttest: 0.4959108\tbest: 0.5048672 (294)\ttotal: 5.84s\tremaining: 27.4s\n",
      "360:\ttest: 0.4943543\tbest: 0.5048672 (294)\ttotal: 6s\tremaining: 27.2s\n",
      "370:\ttest: 0.4948138\tbest: 0.5048672 (294)\ttotal: 6.16s\tremaining: 27.1s\n",
      "380:\ttest: 0.4938804\tbest: 0.5048672 (294)\ttotal: 6.32s\tremaining: 26.9s\n",
      "390:\ttest: 0.4952941\tbest: 0.5048672 (294)\ttotal: 6.48s\tremaining: 26.7s\n",
      "400:\ttest: 0.4971303\tbest: 0.5048672 (294)\ttotal: 6.64s\tremaining: 26.5s\n",
      "410:\ttest: 0.4929384\tbest: 0.5048672 (294)\ttotal: 6.8s\tremaining: 26.3s\n",
      "420:\ttest: 0.4959651\tbest: 0.5048672 (294)\ttotal: 6.96s\tremaining: 26.1s\n",
      "430:\ttest: 0.4965157\tbest: 0.5048672 (294)\ttotal: 7.12s\tremaining: 25.9s\n",
      "440:\ttest: 0.4947938\tbest: 0.5048672 (294)\ttotal: 7.28s\tremaining: 25.7s\n",
      "450:\ttest: 0.4925916\tbest: 0.5048672 (294)\ttotal: 7.44s\tremaining: 25.5s\n",
      "460:\ttest: 0.4954198\tbest: 0.5048672 (294)\ttotal: 7.6s\tremaining: 25.4s\n",
      "470:\ttest: 0.4936884\tbest: 0.5048672 (294)\ttotal: 7.76s\tremaining: 25.2s\n",
      "480:\ttest: 0.4915656\tbest: 0.5048672 (294)\ttotal: 7.92s\tremaining: 25s\n",
      "490:\ttest: 0.4915495\tbest: 0.5048672 (294)\ttotal: 8.08s\tremaining: 24.8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.5048671935\n",
      "bestIteration = 294\n",
      "\n",
      "Shrink model to first 295 iterations.\n",
      "model fit: elapsed = 8.229 num_trees = 295\n",
      "\n",
      "evaluated:\n",
      "metric = NDCG:top=10;type=Exp score = 0.454\n",
      "metric = DCG:top=10;type=Exp score = 9.244\n",
      "metric = MAP:top=10 score = 0.554\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_model('YetiRank')\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"model fit: elapsed = {elapsed:.3f} num_trees = {model.tree_count_}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(pool_test)\n",
    "\n",
    "# Compute metrics on test using original (non-normalized) labels\n",
    "print(\"\\nevaluated:\")\n",
    "compute_metrics(y_test_orig, y_hat_test, q_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
