{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02e2af1-998e-4b33-8220-62270916d947",
   "metadata": {},
   "source": [
    "# Машинное обучение ранжированию с помощью библиотеки CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом примере мы:\n",
    "- увидим как выглядят датасеты для машинного обучения ранжированию, на примере стандартного датасета [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- познакомимся с библиотекой **CatBoost**\n",
    "- научимся решать задачу машинного обучения ранжирования используя алгоритмы, реализованные в **CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import catboost\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Дальше мы будем работать с датасетом MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Мы этого делать не будем т.к. в CatBoost уже встроена возможность загрузить небольшой сабсет MSLR, с которым мы и будем работать дальше.\n",
    "\n",
    "Загрузим этот сабсет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61225ba7-5615-4e17-93e3-cbf592d3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = datasets.msrank_10k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994de0-9f4a-4582-91f4-8ae1813b0df3",
   "metadata": {},
   "source": [
    "Датасет представляет собой обычный табличный датасет из 130 колонок:\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053cf6f-71de-41a9-a255-6e6ce91ea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d21-056f-42d8-a007-966444ab0996",
   "metadata": {},
   "source": [
    "Для удобства присвоим колонкам говорящие имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e3c18-6103-4914-a872-cbc7879fce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "# Assign column names\n",
    "columns = generate_column_names(num_features=136)\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cb1b-4ad1-438f-b6d8-fd1676c34683",
   "metadata": {},
   "source": [
    "Теперь наши данные выглядят красивее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f781c-8850-4dae-b619-cdc7ac0cc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Проведем небольшой EDA.\n",
    "\n",
    "Всего у нас 10000 документов в трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ad7b6-a90a-4eda-a47f-ec9b407cd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360312-89be-4d21-af28-7c24e7871e89",
   "metadata": {},
   "source": [
    "И 10000 документов в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e99fd-93a4-4a60-af94-7e81c7615504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7932d-b65e-4b33-b468-c4ef727f4aa6",
   "metadata": {},
   "source": [
    "Сколько у нас запросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c337181-5898-4889-8e4d-ccc872aea83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_queries_train = df_train['qid'].nunique()\n",
    "num_queries_test = df_test['qid'].nunique()\n",
    "print(f\"Got {num_queries_train} train and {num_queries_test} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd93a2-8714-473c-9a0a-259749f651a3",
   "metadata": {},
   "source": [
    "Получается, у нас примерно по 100 документов на запрос.\n",
    "\n",
    "Это типично, когда, например, для сбора датасета обкачивались и заливались на оценку топ-100 документов поисковой выдачи по случайным запросам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8ba6b-aef3-4a13-884e-65da7f014abd",
   "metadata": {},
   "source": [
    "Теперь посмотрим на распределение таргетов (оценок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e427aaa-d453-4843-b824-4ebfb7897955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d3dc2-54f6-46d1-b238-daed3743a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fddaa-d7ba-453a-aa5f-5bc834be9951",
   "metadata": {},
   "source": [
    "Теперь нам надо представить датасет в формате, который можно подавать на вход катбустовой модели.  \n",
    "Для этого придется разделить его на 3 части:\n",
    "\n",
    "- **y** -- вектор таргетов\n",
    "- **X** -- тензор из фичей\n",
    "- **q** -- вектор из ID запросов, которые позволяют сгруппировать все документы, которые относятся к одному и тому же запросу\n",
    "\n",
    "CatBoost требует, чтобы в векторе **q** одинаковые ID запроса шли подряд (но в отличие от, например, xgboost, не требует их строгой сортированности). Однако в нашем случае никаких дополнительных действий не потребуется т.к. датасет уже и так отсортирован по qid.\n",
    "\n",
    "Убедимся в этом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672a4fc-7cf6-4ee5-a598-286dde967d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['qid'].is_monotonic_increasing)\n",
    "print(df_test['qid'].is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885edf-16c5-4e99-b376-61e72e1b2b93",
   "metadata": {},
   "source": [
    "Сконвертируем датасет в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15870f-9459-48d7-a69d-5cd26c23f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_catboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_catboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_catboost_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем pointwise модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. Мы начнем с простой pointwise модели которая в качестве лосса использует обычное RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0534f6-713f-4fa1-83c6-5d20104c1495",
   "metadata": {},
   "source": [
    "Подготовим пулы катбуста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22758401-b1aa-4eee-a6d5-2dfc257ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_train = catboost.Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "pool_test = catboost.Pool(data=X_test, label=y_test, group_id=q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f73c0-7873-4676-aad0-7eeb1f1a78f7",
   "metadata": {},
   "source": [
    "Зададим целевую метрику, которую будем оптимизировать.  \n",
    "В нашем случае будем использовать NDCG@10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34305a-86c9-429b-b571-dd3d132c5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRIC = 'NDCG:top=10;type=Exp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb13c5-d705-4f42-85cd-e19e5ea66e1f",
   "metadata": {},
   "source": [
    "Подготовим параметры обучения модели, в т.ч.:\n",
    "- целевую метрику\n",
    "- сид генератора случайных чисел\n",
    "- число итераций, после которого останавливаем обучение если в течение данного числа итераций мы не наблюдаем улучшения целевой метрики на валидационном множестве\n",
    "\n",
    "Если хотим обучаться на GPU, то еще надо добавить параметр *task_type=GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842e3be-6a55-4baf-a2e7-6bf63a2a2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'iterations': 1000,            # maximum possible number of trees\n",
    "    'early_stopping_rounds': 100,  # stop if metric does not improve for N rounds\n",
    "    'eval_metric': EVAL_METRIC,    # # metric used for early stopping\n",
    "    'random_seed': 22,\n",
    "    'verbose': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3700ad-b190-4ea5-aa5f-e2999284f73f",
   "metadata": {},
   "source": [
    "Мы будем обучать разные модели, использующие разные лоссы, соответствующие разным алгоритмам машинного обучения ранжированию.  \n",
    "Напишем функцию, которая позволит кастомизировать модель под нужный лосс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caad53-8a10-4a91-bfd5-58399c0fd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(loss_function):\n",
    "    params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "\n",
    "    # Temporary directory that is used by catboost to store additional information\n",
    "    catboost_info_dir = f\"/tmp/catboost_info.{loss_function.lower()}\"\n",
    "\n",
    "    params.update({\n",
    "        'loss_function': loss_function,\n",
    "        'train_dir': str(catboost_info_dir),\n",
    "    })\n",
    "    return catboost.CatBoost(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a3880-e714-4d18-a1a9-9234d01db4dc",
   "metadata": {},
   "source": [
    "Создадим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5d6e5-e4cb-4d31-940c-06e6be853ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model('RMSE')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9414a4-c51b-41f1-8d7f-e7eb3fca9446",
   "metadata": {},
   "source": [
    "И зафитим ее на нашем обучающем множестве.\n",
    "\n",
    "Количество деревьев будет выбрано автоматически с использованием т.н. early stopping -- процесс обучения будем остановлен после того, как на валидационном множестве перестанет расти наша целевая метрика (т.е. NDCG).\n",
    "\n",
    "Для этого передадим в функцию fit() в качестве валидационного множества (параметр eval_set) наш тест-сет.\n",
    "\n",
    "ВНИМАНИЕ: строго говоря, так делать нельзя т.к. приведет к переобучению. По хорошему, мы должны были сначала разбить наш трейн на собственно обучающее и валидационное множества, и передавать в eval_set уже это валидационное множества. А тест-сет надо было сохранить и использовать уже только в самом конце для подсчета финальных скоров. Однако, для простоты, мы так делать не будем, и оставим все это в качестве упражнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f093276-08d9-462a-af6a-39a7e6fd0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: num_trees = {model.tree_count_} elapsed = {elapsed:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913ae1-7037-453f-9a12-e1b4666d1bf3",
   "metadata": {},
   "source": [
    "Видим, что модель состоит из 239 деревьев, и лучший скор NDCG@10 на тесте равен **0.419**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b40b16-abdf-4ad7-a452-daf875366e76",
   "metadata": {},
   "source": [
    "При желании, мы теперь можем сохранить модель в формате cbm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b6fac-7747-4dd4-93d6-c035a8e7a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/tmp/model.cbm\"\n",
    "\n",
    "# Save model\n",
    "model.save_model(model_file)\n",
    "\n",
    "# Load model\n",
    "# model = catboost.CatBoost()\n",
    "# model.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89c7a-0987-4831-98f1-989f75240acf",
   "metadata": {},
   "source": [
    "Получим предикты модели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00327b-7005-44dc-990f-bc9ec5573368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(pool_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp', 'DCG:top=10;type=Exp', 'MAP:top=10']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6fd2e-a19e-492b-aec1-d8824184f980",
   "metadata": {},
   "source": [
    "Мы видим, что значение NDCG@10 на тесте совпало с тем, что вывел сам катбуст во время обучения модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e160-40b5-4609-a01e-c1c0613fc175",
   "metadata": {},
   "source": [
    "## Обучаем YetiRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48a3c-095c-4db0-8d49-8ed7fd488625",
   "metadata": {},
   "source": [
    "Теперь проделаем все то же самое, но на этот раз с использованием алгоритма YetiRank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16b132-99ce-499b-bcdd-539d67008f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model('YetiRank')\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f} num_trees = {model.tree_count_}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(pool_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nEvaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Видно, что теперь модель обучается значительно дольше.\n",
    "\n",
    "Сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = 0.419\n",
    "- а YetiRank выбивает уже NDCG@10 = 0.439!\n",
    "\n",
    "Таким образом мы наглядно видим преимущество pairwise/listwise-подхода над \"наивным\" pointwise-подходом."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
