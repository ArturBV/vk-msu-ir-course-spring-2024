{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02e2af1-998e-4b33-8220-62270916d947",
   "metadata": {},
   "source": [
    "# Машинное обучение ранжированию с помощью библиотеки XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом примере мы:\n",
    "\n",
    "- познакомимся с библиотекой **XGBoost**\n",
    "- научимся решать задачу машинного обучения ранжирования используя алгоритмы, реализованные в **XGBoost**\n",
    "\n",
    "Будем использовать стандартный датасет [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "\n",
    "Подробности про формат датасета можно найти в соседнем тюториале *catboost_ltr.ipynb* по машинному обучению ранжированию с помощью библиотеки **CatBoost**, предполагаем что мы его уже прошли."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import xgboost as xgb\n",
    "# We'll use catboost to download dataset and to compute metrics\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим встроенный в катбуст сабсет датасета MSLR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61225ba7-5615-4e17-93e3-cbf592d3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = datasets.msrank_10k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d21-056f-42d8-a007-966444ab0996",
   "metadata": {},
   "source": [
    "Для удобства присвоим колонкам говорящие имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e3c18-6103-4914-a872-cbc7879fce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "# Assign column names\n",
    "columns = generate_column_names(num_features=136)\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cb1b-4ad1-438f-b6d8-fd1676c34683",
   "metadata": {},
   "source": [
    "Теперь наши данные выглядят красивее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f781c-8850-4dae-b619-cdc7ac0cc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Всего у нас:\n",
    "\n",
    "- 87 запросов и 10000 документов в трейне\n",
    "- 88 запросов и 10000 документов в тесте\n",
    "- 130 колонок: таргет (оценка асессора), id запроса (qid) и вектор из 128 фичей\n",
    "- таргет принимает значения в интервале \\[0,4\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fddaa-d7ba-453a-aa5f-5bc834be9951",
   "metadata": {},
   "source": [
    "Теперь нам надо представить датасет в формате, который можно подавать на вход модели xgboost.  \n",
    "По полной аналогии с тем как мы это делали для catboost, придется разделить его на 3 части:\n",
    "\n",
    "- **y** -- вектор таргетов\n",
    "- **X** -- тензор из фичей\n",
    "- **q** -- вектор из id запросов, которые позволяют сгруппировать все документы, которые относятся к одному и тому же запросу\n",
    "\n",
    "Заметим, что xgboost, в отличие от catboost, требует строгой отсортированности по id запроса. Однако в данном случае нам повезло и датасет уже и так отсортирован по qid.\n",
    "\n",
    "Убедимся в этом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672a4fc-7cf6-4ee5-a598-286dde967d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['qid'].is_monotonic_increasing)\n",
    "print(df_test['qid'].is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885edf-16c5-4e99-b376-61e72e1b2b93",
   "metadata": {},
   "source": [
    "Сконвертируем датасет в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15870f-9459-48d7-a69d-5cd26c23f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xgboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_xgboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_xgboost_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем pointwise модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. Мы начнем с простой pointwise модели которая в качестве лосса использует обычное RMSE.\n",
    "\n",
    "Количество деревьев будем выбирать автоматически с использованием т.н. early stopping -- процесс обучения будем остановлен после того, как на валидационном множестве перестанет расти наша целевая метрика (в нашем случае это NDCG@10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0534f6-713f-4fa1-83c6-5d20104c1495",
   "metadata": {},
   "source": [
    "Создадим объект модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22758401-b1aa-4eee-a6d5-2dfc257ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,            # maximum possible number of trees\n",
    "    objective='reg:squarederror', # RMSE\n",
    "    eval_metric=['ndcg@10'],      # metric used for early stopping\n",
    "    early_stopping_rounds=10,     # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9414a4-c51b-41f1-8d7f-e7eb3fca9446",
   "metadata": {},
   "source": [
    "И зафитим ее на нашем обучающем множестве.  \n",
    "Т.к. мы используем early stopping то передадим в функцию fit() в качестве валидационного множества (параметр eval_set) наш тест-сет (строго говоря так делать нельзя, но мы в данном примере не стремимся к строгости, подробнее этот момент расписан в тюториале про машинное обучение ранжированию с помощью каибуста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f093276-08d9-462a-af6a-39a7e6fd0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"model fit: elapsed = {elapsed:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913ae1-7037-453f-9a12-e1b4666d1bf3",
   "metadata": {},
   "source": [
    "Посмотрим, сколько деревьев содержит модель. Это немного сложнее чем было с катбустом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0b61d-0cc6-4671-97f5-5c2fe55f81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = len(model.get_booster().get_dump())\n",
    "best_iteration = model.best_iteration\n",
    "best_score = model.best_score\n",
    "print(f\"model params: num_trees = {num_trees} best_iteration = {best_iteration} best_score = {best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52632b78-fe55-4d29-8ad9-6d372d74fe97",
   "metadata": {},
   "source": [
    "Видно, что всего модель содержит 13 деревьев, но лучший скор на валидации достигается уже после применения 2х из них.  \n",
    "Поэтому на этапе инференса будет использоваться всего 2 дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b40b16-abdf-4ad7-a452-daf875366e76",
   "metadata": {},
   "source": [
    "При желании, мы можем сохранить эту модель в формате json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b6fac-7747-4dd4-93d6-c035a8e7a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/tmp/model.xgb.json\"\n",
    "\n",
    "# Save model\n",
    "model.save_model(model_file)\n",
    "\n",
    "# Load model\n",
    "# model = xgb.XGBRegressor()\n",
    "# model.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89c7a-0987-4831-98f1-989f75240acf",
   "metadata": {},
   "source": [
    "Получим предикты модели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00327b-7005-44dc-990f-bc9ec5573368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(X_test)\n",
    "print(f\"predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества, тут для удобства и единообразия будем использовать catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp', 'DCG:top=10;type=Exp', 'MAP:top=10']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6fd2e-a19e-492b-aec1-d8824184f980",
   "metadata": {},
   "source": [
    "Видим, что значение NDCG на тесте получилось значительно хуже, чем у катбуста (но, при желании, можно сделать сильно лучше если потюнить параметры модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e160-40b5-4609-a01e-c1c0613fc175",
   "metadata": {},
   "source": [
    "## Обучаем pairwise модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48a3c-095c-4db0-8d49-8ed7fd488625",
   "metadata": {},
   "source": [
    "Теперь проделаем все то же самое, но с использованием алгоритма RankNet.  \n",
    "\n",
    "Для этого вместо *XGBRegressor* будем использовать класс *XGBRanker*, которому в качестве objective передадим 'rank:pairwise'.\n",
    "\n",
    "Также, теперь мы должны передавать в метод fit() наши вектора q_train и q_test, чтобы модель могла сгруппировать документы по запросу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16b132-99ce-499b-bcdd-539d67008f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = xgb.XGBRanker(\n",
    "    n_estimators=1000,          # maximum possible number of trees\n",
    "    objective='rank:pairwise',  # RankNet objective\n",
    "    eval_metric=[\"ndcg@10\"],    # metric used for early stopping\n",
    "    early_stopping_rounds=10,   # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, qid=q_train, eval_set=[(X_test, y_test)], eval_qid=[q_test], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"model fit: elapsed = {elapsed:.3f} num_trees = {model.best_iteration}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nevaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = 0.353\n",
    "- а RankNet выбивает уже NDCG@10 = 0.387\n",
    "\n",
    "Мы опять видим преимущество listwise-подхода над \"наивным\" pointwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f624da-ba38-4179-94ba-d94f0ee43567",
   "metadata": {},
   "source": [
    "И, наконец, попробуем полноценный LambdaRank, для этого:\n",
    "\n",
    "- в качестве objective будем использовать значение 'rank:ndcg'\n",
    "- будем использовать дополнительные параметры lambdarank_pair_method и lambdarank_num_pair_per_sample (про них можно почитать в [документации](https://xgboost.readthedocs.io/en/latest/tutorials/learning_to_rank.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1e723-de86-463d-9a95-e882ea94c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = xgb.XGBRanker(\n",
    "    n_estimators=1000,          # maximum possible number of trees\n",
    "    objective='rank:ndcg',      # LambdaRank objective\n",
    "    lambdarank_pair_method='topk',\n",
    "    lambdarank_num_pair_per_sample=20,\n",
    "    eval_metric=[\"ndcg@10\"],    # metric used for early stopping\n",
    "    early_stopping_rounds=10,   # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, qid=q_train, eval_set=[(X_test, y_test)], eval_qid=[q_test], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"model fit: elapsed = {elapsed:.3f} num_trees = {model.best_iteration}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nevaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806742a-7f08-4cec-a3a7-dd082097bef4",
   "metadata": {},
   "source": [
    "Еще раз сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = 0.353\n",
    "- RankNet выбивает уже NDCG@10 = 0.387\n",
    "- LambdaRank лучше всех и выбивает 0.416\n",
    "\n",
    "Однако, обратим внимание, что, несмотря на то, что pairwise подходы опять победили, абсолютные значения NDCG@10 даже у LambdaRank хуже того, что выбивала простая регрессия в catboost (0.419), не говоря уже от YetiRank!\n",
    "\n",
    "Видно, что \"из коробки\" catboost показывает значительно лучшие результаты, чем xgboost.  \n",
    "Справедливости ради заметим, что мы в наших примерах совсем не пытались тюнить гиперпараметры -- если это проделать, то из xgboost можно \"выжать\" скоры значительно лучше.  \n",
    "Тем не менее, по нашему опыту, на данный момент catboost действительно показывает на задаче ранжирования результаты лучше \"конкурентов\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
