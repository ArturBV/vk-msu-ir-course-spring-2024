{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-historic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://norvig.com/big.txt > train_texts_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "words_occurences = Counter(words(open('train_texts_en.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(word, total_occurences=sum(words_occurences.values())):\n",
    "    '''Probability of `word`. Naive implementation.'''\n",
    "    return words_occurences[word] / total_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_candidates(words):\n",
    "    '''The subset of `words` that appear in the dictionary of words_occurences.'''\n",
    "    output = set()\n",
    "    for word in words:\n",
    "        if word in words_occurences:\n",
    "            output.add(word)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    '''All edits that are one edit away from `word`.'''\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    # <YOUR CODE: generate various candidates>\n",
    "    deletes = [L + R[1:] for L, R in splits]\n",
    "    transposes = [L[:-1] + R[0] + L[-1] + R[1:] for L, R in splits if len(L) > 0 and len(R) > 0]\n",
    "    replaces = [L + c + R[1:] for L, R in splits for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    '''All edits that are 2 edits away from `word`.'''\n",
    "    #<YOUR CODE>\n",
    "    output = set()\n",
    "    for candidate in edits1(word):\n",
    "        output.update(edits1(candidate))\n",
    "    return output\n",
    "\n",
    "def generate_candidates(word):\n",
    "    '''Generate possible spelling corrections for word: 2 edits away is enough.'''\n",
    "    #<YOUR CODE>\n",
    "    return limit_candidates(edits2(word)) or limit_candidates(edits1(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"mestak\"\n",
    "assert type(generate_candidates(word)) == set\n",
    "assert generate_candidates(word) == {'meatal', 'mental', 'mesial', 'metal', 'mistake', 'vestas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(word):\n",
    "    '''Most probable spelling correction for word.'''\n",
    "    return max(generate_candidates(word), key=language_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistake'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"mestak\"\n",
    "correct_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanislav.petrov/.venvs/student/lib64/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"пквкая чейчс погаа\",\n",
    "    \"как проайти ло музея\",\n",
    "    \"как папасть на сайт однакласники\",\n",
    "    \"кто еапичл картмну зевденая очь\",\n",
    "    \"прийдя в МГТУ я был удивлен никого необноружив там...\",\n",
    "    \"Думю ешцъа лет череа 10 ретроспективно просматривотьэ то будкетцц мне невероя тна ин те р но\",\n",
    "    \"crjkmrj ctqxfc dhtvtyb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "used_time = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Pavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses==0.0.53 in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (0.0.53)\n",
      "Requirement already satisfied: regex in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (from sacremoses==0.0.53) (2023.12.25)\n",
      "Requirement already satisfied: six in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (from sacremoses==0.0.53) (1.16.0)\n",
      "Requirement already satisfied: click in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (from sacremoses==0.0.53) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (from sacremoses==0.0.53) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (from sacremoses==0.0.53) (4.64.1)\n",
      "Requirement already satisfied: pypi-kenlm==0.1.20220713 in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (0.1.20220713)\n",
      "Ignoring kenlm: markers 'python_version == \"3.11.*\"' don't match your environment\n",
      "Requirement already satisfied: sortedcontainers==2.4.* in /home/stanislav.petrov/.venvs/student/lib/python3.8/site-packages (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install levenshtein_corrector_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 12:26:10.107 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/vocabs/russian_words_vocab.dict.gz download because of matching hashes\n",
      "2024-04-03 12:26:20.282 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/lang_models/ru_wiyalen_no_punkt.arpa.binary.gz download because of matching hashes\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "model = build_model('levenshtein_corrector_ru', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 22.31it/s]\n"
     ]
    }
   ],
   "source": [
    "t_start = time.perf_counter()\n",
    "results[\"deep_pavlov\"] = {sample: model([sample])[0] for sample in tqdm(samples)}\n",
    "cpu_time = time.perf_counter() - t_start\n",
    "gpu_time = None\n",
    "used_time[\"deep_pavlov\"] = (cpu_time, gpu_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ai-forever/sage.git\n",
    "%cd sage\n",
    "!pip install .\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_names = [\n",
    "    'ai-forever/RuM2M100-1.2B',\n",
    "    'ai-forever/RuM2M100-418M',\n",
    "    'ai-forever/FRED-T5-large-spell',\n",
    "    'ai-forever/T5-large-spell',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fixed_from_samples(model, tokenizer, samples, device='cpu', prefix=''):\n",
    "    samples_copy = [prefix + s for s in samples]\n",
    "    model = model.to(device)\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    tokens = tokenizer(samples_copy, padding=True, return_tensors='pt')\n",
    "    output = model.generate(tokens['input_ids'].to(device), do_sample=True, top_k=50, top_p=0.95, num_return_sequences=1)\n",
    "    results = tokenizer.batch_decode(output.cpu(), skip_special_tokens=True)\n",
    "\n",
    "    all_time = time.perf_counter() - t_start\n",
    "    return dict(zip(samples, results)), all_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▌                                               | 2/4 [01:53<01:43, 52.00s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/stanislav.petrov/.venvs/student/lib64/python3.8/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:40<00:00, 55.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_name in tqdm(model_names):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    prefix = \"Исправь: \" if model_name == \"ai-forever/FRED-T5-large-spell\" else \"\"\n",
    "\n",
    "    _, time_for_gen_cpu = generate_fixed_from_samples(model, tokenizer, samples, device='cpu', prefix=prefix)\n",
    "\n",
    "    fixed_samples, time_for_gen_gpu = generate_fixed_from_samples(model, tokenizer, samples, device=device, prefix=prefix)\n",
    "\n",
    "    used_time[model_name] = (time_for_gen_cpu, time_for_gen_gpu)\n",
    "    results[model_name] = fixed_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu: ms</th>\n",
       "      <th>gpu: ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep_pavlov</th>\n",
       "      <td>45.421960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-1.2B</th>\n",
       "      <td>1551.967742</td>\n",
       "      <td>184.065399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-418M</th>\n",
       "      <td>1075.709530</td>\n",
       "      <td>125.340637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/FRED-T5-large-spell</th>\n",
       "      <td>817.298032</td>\n",
       "      <td>114.211568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/T5-large-spell</th>\n",
       "      <td>691.629125</td>\n",
       "      <td>97.786517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cpu: ms     gpu: ms\n",
       "deep_pavlov                       45.421960         NaN\n",
       "ai-forever/RuM2M100-1.2B        1551.967742  184.065399\n",
       "ai-forever/RuM2M100-418M        1075.709530  125.340637\n",
       "ai-forever/FRED-T5-large-spell   817.298032  114.211568\n",
       "ai-forever/T5-large-spell        691.629125   97.786517"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_used_time = pd.DataFrame(used_time, index=[\"cpu: ms\", \"gpu: ms\"]).T / len(samples) * 1000\n",
    "df_used_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu: rps</th>\n",
       "      <th>gpu: rps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep_pavlov</th>\n",
       "      <td>22.015783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-1.2B</th>\n",
       "      <td>0.644343</td>\n",
       "      <td>5.432852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/RuM2M100-418M</th>\n",
       "      <td>0.929619</td>\n",
       "      <td>7.978258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/FRED-T5-large-spell</th>\n",
       "      <td>1.223544</td>\n",
       "      <td>8.755681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai-forever/T5-large-spell</th>\n",
       "      <td>1.445862</td>\n",
       "      <td>10.226359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cpu: rps   gpu: rps\n",
       "deep_pavlov                     22.015783        NaN\n",
       "ai-forever/RuM2M100-1.2B         0.644343   5.432852\n",
       "ai-forever/RuM2M100-418M         0.929619   7.978258\n",
       "ai-forever/FRED-T5-large-spell   1.223544   8.755681\n",
       "ai-forever/T5-large-spell        1.445862  10.226359"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rps = 1.0 / (df_used_time / 1000)\n",
    "df_rps.columns = [\"cpu: rps\", \"gpu: rps\"]\n",
    "df_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE: пквкая чейчс погаа\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: пквкая чейчс погас\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: Дышу инструкторов какая сейчас погода\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. », «квкая», «чей час погана».\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Клубковская сейчас пока акаюкаюкаюкаюкаюкаюка\n",
      "ai-forever/T5-large-spell\tOUTPUT: korubrjabka obrjerbka\n",
      "######################################################################################################################################################\n",
      "SAMPLE: как проайти ло музея\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: как пройти до музея\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: apart как пройти до музея\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Как пройти по Музея\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Как пройти до музеяХодить по музеям: как пройти до музея1.4 Ак\n",
      "ai-forever/T5-large-spell\tOUTPUT: каkal каkal pravdarти ло мy\n",
      "######################################################################################################################################################\n",
      "SAMPLE: как папасть на сайт однакласники\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: как попасть на сайт однакласники\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: как попасть на сайт одноклассники\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Как попасть на сайт «Одноклассники»\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: как попасть на сайт одноклассники?:как попасть на сайт одноклассники?:как попасть на\n",
      "ai-forever/T5-large-spell\tOUTPUT: как aafargigi nahe ciam\n",
      "######################################################################################################################################################\n",
      "SAMPLE: кто еапичл картмну зевденая очь\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: кто еапичл картину зевденая дочь\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: Интересно кто написал картину зеленая ночь\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. )))) Кто напичл картину «Зеденая ночь».\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: кто написал картину Звездная ночь» кто написал картину Звездная ночь» Кто писал картину Звездная\n",
      "ai-forever/T5-large-spell\tOUTPUT: kaprizhodon zhorgiyo eksl\n",
      "######################################################################################################################################################\n",
      "SAMPLE: прийдя в МГТУ я был удивлен никого необноружив там...\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: придя в моту я был удивлен никого необноружив там...\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: trust прийдя в МГТУ я был удивлен никого необноружив там...\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: Прийдя в МГТУ, я был удивлен, никого не обнаружив там...\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: прийдя в МГТУ я был удивлен никого необнаружив там...прийдя в\n",
      "ai-forever/T5-large-spell\tOUTPUT: рид в   л yдиb\n",
      "######################################################################################################################################################\n",
      "SAMPLE: Думю ешцъа лет череа 10 ретроспективно просматривотьэ то будкетцц мне невероя тна ин те р но\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: думы ешцъа лет через 10 ретроспективно просматривотьэ то будкетцц мне неверия на ин те р но\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: apart Думаю что лет через 10 ретроспективно просматривать это будет мне невероятно интересно\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: .. Думаю, ешцъа лет через 10 ретроспективно просматривать,это буде ТЦЦ. Мне невероятно интерес, но.\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: Думаю ещё лет через 10 ретроспективно просматривать это будет мне невероятно интересно. Думается лет\n",
      "ai-forever/T5-large-spell\tOUTPUT: yezrol era lovет eurekal\n",
      "######################################################################################################################################################\n",
      "SAMPLE: crjkmrj ctqxfc dhtvtyb\n",
      "\n",
      "deep_pavlov\t\t\tOUTPUT: crjkmrj ctqxfc dhtvtyb\n",
      "ai-forever/RuM2M100-1.2B\tOUTPUT: drawings crjkmrj ctqxfc dhtvtyb\n",
      "ai-forever/RuM2M100-418M\tOUTPUT: com/rjkmrj. co/tXfcdHTvTyB.\n",
      "ai-forever/FRED-T5-large-spell\tOUTPUT: crojkmrj ctqxfc dhtvtybd\n",
      "ai-forever/T5-large-spell\tOUTPUT: The story is the sort of story that should be there\n",
      "######################################################################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "to_print = defaultdict(dict)\n",
    "for model_name in results:\n",
    "    for sample in samples:\n",
    "        to_print[sample].update({model_name: results[model_name][sample]})\n",
    "\n",
    "str_result = \"\"\n",
    "for sample in to_print:\n",
    "    str_result += f\"SAMPLE: {sample}\\n\\n\"\n",
    "    for model_name, fixed in to_print[sample].items():\n",
    "        str_result += f\"{model_name}\"\n",
    "        if model_name == 'deep_pavlov':\n",
    "            str_result += '\\t'*2\n",
    "        str_result += f\"\\tOUTPUT: {fixed}\\n\"\n",
    "    str_result += '#' * 150 + '\\n'\n",
    "\n",
    "\n",
    "print(str_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
