{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06efe571-c571-4301-8c84-6a19dea2b9b5",
   "metadata": {},
   "source": [
    "# Домашняя работа по теме \"Машинное обучение ранжированию\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом ДЗ мы:\n",
    "- научимся работать со стандартным датасетом для машинного обучения ранжированию [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- попробуем применить на практике все то, чему мы научились на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим датасет MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Строго говоря, он состоит их 2х частей:\n",
    "\n",
    "- основной датасет MSLR-WEB30K -- он содержит более 30 тыс. запросов\n",
    "- \"маленький\" датасет MSLR-WEB10K, который содержит только 10 тыс. запросов и является случайным сэмплом датасета MSLR-WEB30K\n",
    "\n",
    "в этом ДЗ мы будем работать с MSLR-WEB10K, т.к. полная версия датасета может просто не поместиться у нас в RAM (и, тем более, в память видеокарты если мы учимся на GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf35bd-9729-48bb-975d-a955b8bd1c56",
   "metadata": {},
   "source": [
    "Будем считать, что мы самостоятельно скачали датасет с официального сайта, поместили его в папку КОРЕНЬ-ЭТОЙ-РЕПЫ/data/mslr-web10k и раззиповали.\n",
    "\n",
    "В результате у нас должна получиться следующая структура папок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06baa8-44fe-420b-bad5-4c6f63a66544",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d76cb-2eaa-4b48-be86-ea09a25e2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../data/mslr-web10k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0a87e-eb4a-4b4a-a6b3-0419e29ae539",
   "metadata": {},
   "source": [
    "Заметим, что датасет довольно большой, он весит 7.7 GB.\n",
    "\n",
    "Он состоит из нескольких фолдов, которые по сути представляют из себя разные разбиения одних и тех же данных на обучающее, валидационное и тестовые множеста.\n",
    "\n",
    "Дальше мы будем использовать только первый фолд: Fold1.\n",
    "\n",
    "Заглянем внутрь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa74835-7d91-4c3a-badb-e268027cff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../data/mslr-web10k/Fold1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5ccf5-d83e-45e6-bd9b-3a6c729925c6",
   "metadata": {},
   "source": [
    "Видим, что у нас 3 файла с говорящими названиями, соответсвующими сплитам нашего датасета.\n",
    "\n",
    "Посмотрим на содержимое одного из файлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a1401-1e31-4c01-8eae-daf673d8736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 ../../data/mslr-web10k/Fold1/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f4fa9-9ba3-457f-8bf2-f9a7b3112e91",
   "metadata": {},
   "source": [
    "Видим, что данные лежат в знакомом нам по семинару формате:\n",
    "\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "В файле qid и все-фичи кодируются в формате КЛЮЧ:ЗНАЧЕНИЕ, напр. 130:116 -- тут 130 это номер фичи, а 116 -- ее значение.\n",
    "\n",
    "Такой формат в мире машинного обучения часто называют svm light формат (в честь когда-то популярной библиотеки SVM-Light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bba78-f04f-478b-b3dc-89c9011cb697",
   "metadata": {},
   "source": [
    "Напишем немного вспомогательного кода для загрузки этого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c29b4f-0b79-4259-b079-fdc589d77ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "    \n",
    "def load_svmlight_file(input_file, max_num_lines=0):\n",
    "    \"\"\"Loads dataset split in SVM-Light format\"\"\"\n",
    "    def _parse_field(field):\n",
    "        parts = field.split(':')\n",
    "        if len(parts) != 2:\n",
    "            raise Exception(f\"invalid number of parts in field {field}\")\n",
    "        return parts\n",
    "\n",
    "    num_features = 136\n",
    "    exp_num_fields = num_features + 2\n",
    "    num_lines = 0\n",
    "    X = []\n",
    "    with open(input_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                num_lines += 1\n",
    "                                  \n",
    "                # Parse into fields\n",
    "                fields = line.rstrip().split(' ')\n",
    "                num_fields = len(fields)\n",
    "                if num_fields != exp_num_fields:\n",
    "                    raise Exception(f\"invalid number of fields {num_fields}\")\n",
    "    \n",
    "                # Parse every field\n",
    "                label = int(fields[0])\n",
    "                _, qid_str = _parse_field(fields[1])\n",
    "                qid = int(qid_str)\n",
    "                x = [label, qid]\n",
    "                for field in fields[2:]:\n",
    "                    _, feature_str = _parse_field(field)\n",
    "                    feature = float(feature_str)\n",
    "                    x.append(feature)\n",
    "    \n",
    "                # Add new object\n",
    "                X.append(x)\n",
    "                if num_lines % 50000 == 0:\n",
    "                    print(num_lines)\n",
    "                if max_num_lines > 0 and num_lines == max_num_lines:\n",
    "                    print(f\"WARNING: stop loading, line limit reached: max_num_lines = {max_num_lines} input_file = {input_file}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error at line {num_lines} in {input_file}\") from e\n",
    "    \n",
    "    # To pandas\n",
    "    X = np.asarray(X)\n",
    "    df = pd.DataFrame(X, columns=generate_column_names(num_features))\n",
    "    print(f\"Loaded SVM-Light file {input_file}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa292cb3-e516-423c-a9b4-315123bddfea",
   "metadata": {},
   "source": [
    "И теперь загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25649947-a7ef-4cbd-8403-7e7456c28327",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dir = pathlib.Path(\"../../data/mslr-web10k/Fold1\")\n",
    "\n",
    "df_train = load_svmlight_file(fold_dir.joinpath(\"train.txt\"), max_num_lines=20000)\n",
    "df_valid = load_svmlight_file(fold_dir.joinpath(\"vali.txt\"), max_num_lines=5000)\n",
    "df_test = load_svmlight_file(fold_dir.joinpath(\"test.txt\"), max_num_lines=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994de0-9f4a-4582-91f4-8ae1813b0df3",
   "metadata": {},
   "source": [
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053cf6f-71de-41a9-a255-6e6ce91ea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051e93-845b-45f1-bad8-21020180737e",
   "metadata": {},
   "source": [
    "Т.е. теперь мы видим что данные доступны в точно таком же виде, как это было в семинаре."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Проведем небольшой EDA.\n",
    "\n",
    "Всего у нас 20000 документов в трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ad7b6-a90a-4eda-a47f-ec9b407cd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b79a0-72f8-4c15-9580-9c7c3c22910a",
   "metadata": {},
   "source": [
    "5000 документов в валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2979156-c309-43b9-95a0-d15bc9e594e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_valid.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360312-89be-4d21-af28-7c24e7871e89",
   "metadata": {},
   "source": [
    "И 5000 документов в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e99fd-93a4-4a60-af94-7e81c7615504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7932d-b65e-4b33-b468-c4ef727f4aa6",
   "metadata": {},
   "source": [
    "Сколько у нас запросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c337181-5898-4889-8e4d-ccc872aea83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_queries_train = df_train['qid'].nunique()\n",
    "num_queries_valid = df_valid['qid'].nunique()\n",
    "num_queries_test = df_test['qid'].nunique()\n",
    "print(f\"Got {num_queries_train} train, {num_queries_valid} valid and {num_queries_test} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. \n",
    "\n",
    "Объявим класс модели, который надо будем заимлементить в этом ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab90707-f1b8-4283-ac22-2643baa4ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, df_train, df_valid):\n",
    "        pass\n",
    "\n",
    "    def predict(self, df_test):\n",
    "        return np.random.rand(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e513b-7c4b-41bf-88f1-8bc5faf3a5dc",
   "metadata": {},
   "source": [
    "Создадим и применим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f45c2-bbd7-40e6-89a0-41e185621f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Model()\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(df_train, df_valid)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(df_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "\n",
    "# Get test targets and groups\n",
    "y_test = df_test['label'].to_numpy()\n",
    "q_test = df_test['qid'].to_numpy().astype('uint32')\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Ожидаем, что ваша модель покажет результаты выше бейзлайна!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
